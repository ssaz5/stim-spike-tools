{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, interpolate\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import sqlite3\n",
    "import zlib\n",
    "\n",
    "import msgpack\n",
    "\n",
    "try:\n",
    "    buffer\n",
    "except NameError:\n",
    "    # Python 3\n",
    "    buffer = bytes\n",
    "\n",
    "\n",
    "class MWK2Reader(object):\n",
    "\n",
    "    _compressed_text_type_code = 1\n",
    "    _compressed_msgpack_stream_type_code = 2\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self._conn = sqlite3.connect(filename)\n",
    "        self._unpacker = msgpack.Unpacker(raw=False, strict_map_key=False)\n",
    "\n",
    "    def close(self):\n",
    "        self._conn.close()\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, tb):\n",
    "        self.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def _decompress(data):\n",
    "        return zlib.decompress(data, -15)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for code, time, data in self._conn.execute('SELECT * FROM events'):\n",
    "            if not isinstance(data, buffer):\n",
    "                yield (code, time, data)\n",
    "            else:\n",
    "                try:\n",
    "                    obj = msgpack.unpackb(data, raw=False)\n",
    "                except msgpack.ExtraData:\n",
    "                    # Multiple values, so not valid compressed data\n",
    "                    pass\n",
    "                else:\n",
    "                    if isinstance(obj, msgpack.ExtType):\n",
    "                        if obj.code == self._compressed_text_type_code:\n",
    "                            yield (code,\n",
    "                                   time,\n",
    "                                   self._decompress(obj.data).decode('utf-8'))\n",
    "                            continue\n",
    "                        elif (obj.code ==\n",
    "                              self._compressed_msgpack_stream_type_code):\n",
    "                            data = self._decompress(obj.data)\n",
    "                self._unpacker.feed(data)\n",
    "                try:\n",
    "                    while True:\n",
    "                        yield (code, time, self._unpacker.unpack())\n",
    "                except msgpack.OutOfData:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_bandpass(data, fs, flow, fhigh):\n",
    "    wl = flow / (fs / 2.)\n",
    "    wh = fhigh / (fs / 2.)\n",
    "    wn = [wl, wh]\n",
    "\n",
    "    # Designs a 2nd-order Elliptic band-pass filter which passes\n",
    "    # frequencies between 0.03 and 0.6, an with 0.1 dB of ripple\n",
    "    # in the passband, and 40 dB of attenuation in the stopband.\n",
    "    # The question is, do we really want to use IIR filter design?\n",
    "    # Isn't it the case that IIR filters introduce refractory period\n",
    "    # artifacts, and thus FIRs are preferred in practice?\n",
    "    b, a = signal.ellip(2, 0.1, 40, wn, 'bandpass', analog=False)\n",
    "    # To match Matlab output, we change default padlen from\n",
    "    # 3*(max(len(a), len(b))) to 3*(max(len(a), len(b)) - 1)\n",
    "    return signal.filtfilt(b, a, data, padlen=3*(max(len(a),len(b))-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_artefacts_ind(signal, samp_on, fs=20000, art_time_usec=900, v_thres = 100):\n",
    "    for i in range(len(samp_on)):\n",
    "        pre_ = 1000\n",
    "        post_ = 2000\n",
    "        \n",
    "        \n",
    "#         peaks = np.where(np.abs(sub_signal) > 150) #find_peaks(-sub_signal, 300)\n",
    "        sub_signal = apply_bandpass(signal[samp_on[i]-pre_: samp_on[i]+post_], 20000, 1000,5000)\n",
    "        peaks = find_peaks(-sub_signal, v_thres)\n",
    "        sub_signal = signal[samp_on[i]-pre_: samp_on[i]+post_]\n",
    "#         print('Number of Peaks: ', len(peaks[0]))\n",
    "\n",
    "\n",
    "        art_time_sec = art_time_usec/1e6\n",
    "        art_len_pre = int(fs*art_time_sec/3)\n",
    "        art_len_post = int(fs*art_time_sec)\n",
    "#         print('Artefact length: ', art_len)\n",
    "\n",
    "\n",
    "\n",
    "        start = -pre_\n",
    "        x_ = []\n",
    "        for peak in peaks[0]:\n",
    "            x_.append(np.arange(start,peak - pre_ - art_len_pre))\n",
    "            if peak - pre_ > start:\n",
    "                start = peak - pre_ + art_len_post\n",
    "        x_.append(np.arange(start, post_))\n",
    "        x = np.concatenate(x_)\n",
    "        interpolator_signal = interpolate.interp1d(x, sub_signal[x+pre_], fill_value='extrapolate')\n",
    "        sig_interp = interpolator_signal(np.arange(-pre_,post_))\n",
    "\n",
    "        signal[samp_on[i]-pre_: samp_on[i]+post_] = sig_interp\n",
    "        \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_artefacts(signal, fs=20000, art_time_usec=900, v_thres = 100, flow=1000, fhigh=5000):\n",
    "    sub_signal = apply_bandpass(signal, fs = 20000, flow = 1000,fhigh = 5000)\n",
    "    peaks = find_peaks(-sub_signal, v_thres)\n",
    "    sub_signal = signal\n",
    "    post_ = len(signal)\n",
    "\n",
    "    art_time_sec = art_time_usec/1e6\n",
    "    art_len_pre = int(fs*art_time_sec/3)\n",
    "    art_len_post = int(fs*art_time_sec)\n",
    "\n",
    "    pre_ = 0\n",
    "\n",
    "    start = -pre_\n",
    "    x_ = []\n",
    "    for peak in peaks[0]:\n",
    "        x_.append(np.arange(start,peak - pre_ - art_len_pre))\n",
    "        if peak - pre_ > start:\n",
    "            start = peak - pre_ + art_len_post\n",
    "    x_.append(np.arange(start, post_))\n",
    "    x = np.concatenate(x_)\n",
    "    interpolator_signal = interpolate.interp1d(x, sub_signal[x+pre_], fill_value='extrapolate')\n",
    "    sig_interp = interpolator_signal(np.arange(-pre_,post_))\n",
    "\n",
    "    signal = sig_interp\n",
    "        \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intan header file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the utility scripts available on Intan's website, you must first make the `intanutil` package available to your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sys.path.insert(0, '/Users/etotheipiplusone/Dropbox (MIT)/load_intan_rhd_format/')\n",
    "sys.path.insert(0, '../load_intan_rhd_format/load_intan_rhd_format/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_intan_rhd_format import read_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDataPath = \"/braintree/data2/active/users/ssazaidi/projects/normalizers-pIT/monkeys/oleo/\"\n",
    "# directory_path = rawDataPath+\"intanraw/oleo_stimulation_210816_121924/\"\n",
    "# directory_path = rawDataPath+\"intanraw/oleo_stimulation_210813_134444/\"\n",
    "directory_path = rawDataPath+\"intanraw/oleo_normalizers-pIT_211206_121917/\"\n",
    "\n",
    "\n",
    "# rawDataPath = \"/braintree/data2/active/users/ssazaidi/projects/normalizers/monkeys/oleo/\"\n",
    "# directory_path = rawDataPath+\"intanraw/oleo_normalizers_210813_132632/\"\n",
    "\n",
    "# directory_path = \"/braintree/data2/active/users/ssazaidi/rough/comb_stimulation/oleo_stimulation-2_210802_154413/\"\n",
    "filename = Path(directory_path+ \"info.rhd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading Intan Technologies RHD2000 Data File, Version 2.0\n",
      "\n",
      "n signal groups 11\n",
      "Found 192 amplifier channels.\n",
      "Found 18 auxiliary input channels.\n",
      "Found 6 supply voltage channels.\n",
      "Found 1 board ADC channel.\n",
      "Found 2 board digital input channels.\n",
      "Found 0 board digital output channels.\n",
      "Found 0 temperature sensors channels.\n",
      "\n",
      "Header file contains no data.  Amplifiers were sampled at 20.00 kS/s.\n",
      "Done!  Elapsed time: 0.1 seconds\n"
     ]
    }
   ],
   "source": [
    "# from load_intan_rhd_format import read_data\n",
    "# from intanutils import read_data\n",
    "\n",
    "# filename = Path('oleo_normalizers_210206/info.rhd')\n",
    "assert filename.exists()\n",
    "file_data = read_data(filename)\n",
    "# file_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We are just going to define some constants below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numChannels = len(file_data['amplifier_channels'])\n",
    "samplingFrequency = file_data['frequency_parameters']['amplifier_sample_rate'] # in Hz\n",
    "timeBinSize = 0.01 # in seconds\n",
    "timeBase = np.arange(-.1, .39, timeBinSize) # in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = Path(directory_path+'time.dat')\n",
    "fid = open(filename, 'r')\n",
    "filesize = os.path.getsize(filename) # in bytes\n",
    "num_samples = filesize // 4 # int32 = 4 bytes\n",
    "t = np.fromfile(fid, 'int32', num_samples)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -101087  -101086  -101085 ... 14792990 14792991 14792992]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = t / samplingFrequency # in seconds\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplingFrequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image presentation times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the time points at which an image/stimuli is presented, we read the digital input data file 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = Path(directory_path+ 'board-DIGITAL-IN-02.dat')\n",
    "fid = open(filename, 'r')\n",
    "filesize = os.path.getsize(filename) # in bytes\n",
    "num_samples = filesize // 2 # uint16 = 2 bytes\n",
    "din02 = np.fromfile(fid, 'uint16', num_samples)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay particular notice to the sampling rate, $F_s$, measured in Hertz. Typically used values are between 20 kHz and 30 kHz. This is because you want it to be large enough to capture even the biggest voltage changes. Sodium channel depolarization takes about $200 \\mu s$, which is 5 Hz. The action potential will rise an fall in this interval. Empirically, it is measured to be about 8 Hz, and the sampling theorem prescribes a frequency of 16 Hz minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14894080"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(din02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "din02[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print( (din02[:-1] < din02[1:]).sum() )\n",
    "samp_on, = np.nonzero(din02[:-1] < din02[1:]) # Look for 0->1 transitions\n",
    "samp_on = samp_on + 1 # Previous line returns indexes of 0s seen before spikes, but we want indexes of first spikes\n",
    "# samp_on = samp_on * 1_000_000 / samplingFrequency # times in us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  120727   125373   130035 ... 14755568 14760238 14764908]\n"
     ]
    }
   ],
   "source": [
    "print(samp_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samp_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photodiode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = Path(directory_path+'board-ANALOG-IN-1.dat')\n",
    "fid = open(filename, 'r')\n",
    "filesize = os.path.getsize(filename) # in bytes\n",
    "num_samples = filesize // 2 # uint16 = 2 bytes\n",
    "v_diode = np.fromfile(fid, 'uint16', num_samples)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "v_diode = (v_diode - 32768) * 0.0003125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981250000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(v_diode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2af9ab2c2b90>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(0)\n",
    "# plt.plot(din02)\n",
    "plt.plot(v_diode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14894080"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v_diode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(t[samp_on[30]:samp_on[30]+1000] / samplingFrequency * 1000. - (t[samp_on[30]] / samplingFrequency * 1000.), v[samp_on[30]:samp_on[30]+1000])\n",
    "# plt.show()\n",
    "\n",
    "# ##########\n",
    "# # Analytic \n",
    "# ##########\n",
    "# # from scipy.signal import hilbert, chirp\n",
    "# # analytic_signal = hilbert(v[6948500:6952000])\n",
    "# # amplitude_envelope = np.abs(analytic_signal)\n",
    "# # plt.plot(v[6948500:6952000], label='signal')\n",
    "# # plt.plot(amplitude_envelope, label='envelope')\n",
    "# # plt.show()\n",
    "\n",
    "\n",
    "# ##########\n",
    "# # Bandpass \n",
    "# ##########\n",
    "# # def _apply_bandpass(data, f_sampling, f_low, f_high):\n",
    "# #     wl = f_low / (f_sampling / 2.)\n",
    "# #     wh = f_high / (f_sampling / 2.)\n",
    "# #     wn = [wl, wh]\n",
    "    \n",
    "# #     # Designs a 2nd-order Elliptic band-pass filter which passes\n",
    "# #     # frequencies between 0.03 and 0.6, an with 0.1 dB of ripple\n",
    "# #     # in the passband, and 40 dB of attenuation in the stopband.\n",
    "# #     b, a = signal.ellip(2, 0.1, 40, wn, 'bandpass', analog=False)\n",
    "# #     # To match Matlab output, we change default padlen from\n",
    "# #     # 3*(max(len(a), len(b))) to 3*(max(len(a), len(b)) - 1)\n",
    "# #     return signal.filtfilt(b, a, data, padlen=3*(max(len(a),len(b))-1))\n",
    "\n",
    "# # filtered_v = _apply_bandpass(v, 20000, 100, 6000)\n",
    "# # plt.plot(filtered_v[original_t[0]: original_t[0]+1000])\n",
    "# # plt.show()\n",
    "\n",
    "# ##########\n",
    "# # Peak \n",
    "# ##########\n",
    "# # s = v[original_t[0]: original_t[0]+1000]\n",
    "\n",
    "# # q_u = np.zeros(s.shape)\n",
    "# # q_l = np.zeros(s.shape)\n",
    "\n",
    "# # u_x = [0,]\n",
    "# # u_y = [s[0],]\n",
    "\n",
    "# # l_x = [0,]\n",
    "# # l_y = [s[0],]\n",
    "\n",
    "# # for k in range(1,len(s)-1):\n",
    "# #     if (np.sign(s[k]-s[k-1])==1) and (np.sign(s[k]-s[k+1])==1):\n",
    "# #         u_x.append(k)\n",
    "# #         u_y.append(s[k])\n",
    "\n",
    "# #     if (np.sign(s[k]-s[k-1])==-1) and ((np.sign(s[k]-s[k+1]))==-1):\n",
    "# #         l_x.append(k)\n",
    "# #         l_y.append(s[k])\n",
    "        \n",
    "# # u_x.append(len(s)-1)\n",
    "# # u_y.append(s[-1])\n",
    "\n",
    "# # l_x.append(len(s)-1)\n",
    "# # l_y.append(s[-1])\n",
    "\n",
    "# # u_p = interpolate.interp1d(u_x,u_y, kind = 'cubic',bounds_error = False, fill_value=0.0)\n",
    "# # l_p = interpolate.interp1d(l_x,l_y,kind = 'cubic',bounds_error = False, fill_value=0.0)\n",
    "\n",
    "# # #Evaluate each model over the domain of (s)\n",
    "# # for k in range(0,len(s)):\n",
    "# #     q_u[k] = u_p(k)\n",
    "# #     q_l[k] = l_p(k)\n",
    "    \n",
    "# # plt.plot(s)\n",
    "# # plt.plot(q_u,'r')\n",
    "# # plt.plot(q_l,'g')\n",
    "# # plt.grid(True)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(samp_on), len(peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(samp_on), max(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WORKS!\n",
    "\n",
    "\n",
    "\n",
    "# peaks, _ = find_peaks(v_diode, height=1)\n",
    "# peaks = np.asarray([p for p in peaks if v_diode[p] > 1])\n",
    "# plt.plot(v_diode)\n",
    "# plt.plot(peaks, v_diode[peaks], \"x\")\n",
    "# plt.show()\n",
    "\n",
    "p = []\n",
    "\n",
    "# for i, samp in enumerate(samp_on):\n",
    "# #     print(f'{i} Sample on (us): {samp}')\n",
    "#     peak_range = peaks[(peaks >= samp) & (peaks < (samp + 100_000))]\n",
    "# #     print(f'Peak range {peak_range}')\n",
    "#     p.append(min( peak_range ))\n",
    "# #     print(f'Photodiode on (us): {p}')\n",
    "# #     print(f'Difference: {(p - samp) / samplingFrequency * 1000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks, _ = find_peaks(v_diode, height=0)  # Find all peaks\n",
    "# peaks = np.asarray([p for p in peaks if v_diode[p] > 1])  # Apply threshold\n",
    "# photodiode_on = np.asarray([min(peaks[(peaks >= s) & (peaks < (s + 100_000))]) for s in samp_on])\n",
    "# len(photodiode_on)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photodiode_on_ = photodiode_on * 1000 / samplingFrequency\n",
    "photodiode_on_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_on_ = samp_on * 1000 / samplingFrequency\n",
    "samp_on_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average delay between when the signal was sent to when the image was seen is about 36 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(photodiode_on_ - samp_on_) # in ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, `photodiode_on` contains trial times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MWKReader MWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filepath = rawDataPath + 'mworksraw/datamaco-stim_corners-20210816-121642.mwk2'\n",
    "\n",
    "# filepath = rawDataPath + 'mworksraw/datamaco-stim_corners-20210813-134320.mwk2'\n",
    "\n",
    "filepath = rawDataPath + 'mworksraw/datamaco-stim_corners-20210825-141606.mwk2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with MWK2Reader(filepath) as event_file:\n",
    "    code_to_name, name_to_code = {}, {}\n",
    "    for code, time, data in event_file:\n",
    "        if code == 0 and not code_to_name:\n",
    "            code_to_name = dict((c, data[c]['tagname']) for c in data)\n",
    "            name_to_code = dict((data[c]['tagname'], c) for c in data)\n",
    "            break\n",
    "# code_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\n",
    "            name_to_code['stim_key'],\n",
    "            name_to_code['stim_current'],\n",
    "            name_to_code['stim_id'],\n",
    "            name_to_code['stim_num_pulses'],\n",
    "            name_to_code['stim_pulse_period'],\n",
    "            name_to_code['trial_start_line'],\n",
    "            name_to_code['correct_fixation'],\n",
    "            name_to_code['stimulus_presented'], #,\n",
    "            # Other meta data\n",
    "            name_to_code['stim_on_time'],\n",
    "            name_to_code['stim_off_time'],\n",
    "            name_to_code['stim_on_delay'],\n",
    "            name_to_code['stimulus_size'],\n",
    "            name_to_code['fixation_window_size'],\n",
    "            name_to_code['fixation_point_size_min'],\n",
    "        ]\n",
    "\n",
    "data_dict = {\n",
    "    'code': [],\n",
    "    'name': [],\n",
    "    'time': [],\n",
    "    'data': [],\n",
    "}\n",
    "with MWK2Reader(filepath) as event_file:\n",
    "    for code, time, data in event_file:\n",
    "        if code in codes:\n",
    "            data_dict['code'].append(code)\n",
    "            data_dict['name'].append(code_to_name[code])\n",
    "            data_dict['time'].append(time)\n",
    "            data_dict['data'].append(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [\n",
    "            name_to_code['stim_num_pulses'],\n",
    "            name_to_code['stim_pulse_period']\n",
    "        ]\n",
    "\n",
    "names = ['stim_num_pulses',\n",
    "                    'stim_pulse_period']\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    'name': [],\n",
    "    'data': [],\n",
    "}\n",
    "with MWK2Reader(filepath) as event_file:\n",
    "    for code, time, data in event_file:\n",
    "        if code in codes and data != 1:\n",
    "            data_dict['name'].append(code_to_name[code])\n",
    "            data_dict['data'].append(data)\n",
    "            \n",
    "            if (np.all([i in data_dict['name'] for i in names])):\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['stim_pulse_period',\n",
       "  'stim_pulse_period',\n",
       "  'stim_pulse_period',\n",
       "  'stim_num_pulses'],\n",
       " 'data': [10000, 10000, 10000, 10]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "names = ['stim_num_pulses',\n",
    "                    'stim_pulse_period']\n",
    "np.all([i in ['stim_num_pulses', 'stim_pulse_peri'] for i in names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(code_to_name_old),  len(code_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(filepath, names, time_range=[]):\n",
    "    data_dict = {\n",
    "        'code': [],\n",
    "        'name': [],\n",
    "        'time': [],\n",
    "        'data': [],\n",
    "    }\n",
    "    \n",
    "    with MWK2Reader(filepath) as event_file:\n",
    "        code_to_name, name_to_code = {}, {}\n",
    "        for code, time, data in event_file:\n",
    "            if code == 0 and not code_to_name:\n",
    "                code_to_name = dict((c, data[c]['tagname']) for c in data)\n",
    "                name_to_code = dict((data[c]['tagname'], c) for c in data)\n",
    "                break\n",
    "        codes = [name_to_code[name] for name in names ]\n",
    "        \n",
    "        if time_range:\n",
    "            for code, time, data in event_file:\n",
    "                if code in codes and np.any(np.logical_and(time > time_range[0] , time < time_range[1])):\n",
    "                    data_dict['code'].append(code)\n",
    "                    data_dict['name'].append(code_to_name[code])\n",
    "                    data_dict['time'].append(time)\n",
    "                    data_dict['data'].append(data)\n",
    "        else:\n",
    "            for code, time, data in event_file:\n",
    "                if code in codes:\n",
    "                    data_dict['code'].append(code)\n",
    "                    data_dict['name'].append(code_to_name[code])\n",
    "                    data_dict['time'].append(time)\n",
    "                    data_dict['data'].append(data)\n",
    "    data_df = pd.DataFrame(data_dict)\n",
    "    data_df = data_df.sort_values(by='time').reset_index(drop=True)\n",
    "    return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = np.array([[0, 10], [15,20], [100,108], [2, 12]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 25\n",
    "np.any(np.logical_and(number > time_range[0],  number < time_range[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_events = get_events(filepath, ['eye_h', 'eye_v'], time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = [stimulus_presented_df.time.values - 50 * 1000 , stimulus_presented_df.time.values + 300 * 1000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.DataFrame(data_dict)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df.loc[data_df['name'] == 'stim_current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_events = data_df.loc[data_df['name'] == 'stim_current'].reset_index(drop=True)\n",
    "id_events = data_df.loc[data_df['name'] == 'stim_id'].reset_index(drop=True)\n",
    "key_events = data_df.loc[data_df['name'] == 'stim_key'].reset_index(drop=True)\n",
    "stimulus_presented_df = data_df[data_df.name == 'stimulus_presented'].reset_index(drop=True)\n",
    "correct_fixation_df = data_df[data_df.name == 'correct_fixation'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `empty` data (i.e. -1) before the experiment actually began and after it had already ended\n",
    "correct_fixation_df = correct_fixation_df[stimulus_presented_df.data != -1].reset_index(drop=True)\n",
    "stimulus_presented_df = stimulus_presented_df[stimulus_presented_df.data != -1].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_events), len(current_events), len(key_events), len(stimulus_presented_df), len(correct_fixation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_times = np.array([row.time for i, row in current_events.iterrows()])\n",
    "id_times = np.array([row.time for i, row in id_events.iterrows()])\n",
    "key_times = np.array([row.time for i, row in key_events.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_indices(events, df = False, delay_sec= 1):\n",
    "    if df:\n",
    "        times = np.array([row.time for i, row in events.iterrows()])\n",
    "    else:\n",
    "        times = np.array([i.time for i in events])\n",
    "#     print(len(times))\n",
    "    diff_times = np.diff(times)\n",
    "#     print(len(diff_times))\n",
    "\n",
    "    trials = []\n",
    "\n",
    "    mini_trial = [0]\n",
    "\n",
    "    for i, t in enumerate(diff_times):\n",
    "        if t < delay_sec*1e6:\n",
    "            mini_trial.append(i+1)\n",
    "        else:\n",
    "            trials.append(mini_trial)\n",
    "            mini_trial = [i+1]\n",
    "    trials.append(mini_trial)\n",
    "    print(i, len(trials))\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(current_times))\n",
    "print(np.max(current_times))\n",
    "print(np.max(current_times) - np.min(current_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.max(current_times) - np.min(current_times))/(60*60*1000*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((current_times))\n",
    "print(current_times[0], current_times[1], np.diff(current_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_trials = get_trial_indices(current_events, df=True, delay_sec=0.5)\n",
    "id_trials = get_trial_indices(id_events, df=True, delay_sec = 0.5)\n",
    "key_trials = get_trial_indices(key_events, df=True,  delay_sec = 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.array(current_events.iloc[current_trial].data) for current_trial in current_trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in key_trials:\n",
    "    if len(trial) > 8:\n",
    "        print([key_events.iloc[i].data for i in trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(np.diff(current_times), 'stone')\n",
    "# h = plt.hist(np.diff(id_times), 'rice' )\n",
    "# plt.hist(np.diff(key_times), 50)\n",
    "print(np.median(np.diff(current_times)), np.mean(np.diff(current_times)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[0][0], h[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.diff(id_times) < np.mean(np.diff(id_times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(id_trials)\n",
    "# [np.array(id_events.iloc[i].data) for i in id_trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(i.data, j.data, i.time, j.time, i.time-j.time) for (_,i), (_,j) in zip(key_events.iterrows(),id_events.iterrows())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_len = 0\n",
    "for i in id_trials:\n",
    "    id_len += len(i)\n",
    "    \n",
    "print(id_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_events.iloc[key_trials[-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(current_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[current_trials[i], np.array(current_events.iloc[current_trials[i]].data)] for i in range(len(current_trials))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(current_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_events_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id_trial in id_trials:\n",
    "#     print(np.array(id_events.iloc[id_trial].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_id = []\n",
    "correct_current = []\n",
    "\n",
    "curr_idx = 0\n",
    "while np.all(np.array(current_events.iloc[current_trials[curr_idx]].data) == 1):\n",
    "    curr_idx += 1\n",
    "\n",
    "for i in range(len(id_trials)):\n",
    "#     print((current_times[current_trials[i][0]] - id_times[id_trials[i][0]]), (current_times[current_trials[i+1][0]] - id_times[id_trials[i][0]]))\n",
    "#     print((current_times[current_trials[i][-1]] - id_times[id_trials[i][-1]]), (current_times[current_trials[i+1][-1]] - id_times[id_trials[i][-1]]))\n",
    "\n",
    "    \n",
    "    current_trial = current_trials[curr_idx]\n",
    "    id_trial = id_trials[i]\n",
    "    \n",
    "    if '' in np.array(id_events.iloc[id_trial].data):\n",
    "#         print(np.array(id_events.iloc[id_trial].data))\n",
    "#         print('current: ', current_trial, np.array(current_events.iloc[current_trial].data))        \n",
    "        \n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    if len(id_trial) > 8:\n",
    "        \n",
    "#         print('ID Trial Number: ', i, \"\\tCurrent Trial Number: \", curr_idx)\n",
    "#         print('id', np.array(id_events.iloc[id_trial].data), np.array(id_events.iloc[id_trials[i+1]].data))\n",
    "#         print('current', np.array(current_events.iloc[current_trial].data), np.array(current_events.iloc[current_trials[curr_idx+1]].data))\n",
    "#         print()\n",
    "        id_trial = id_trial[-8:]\n",
    "        \n",
    "    if len(id_trial) < 8 or i in [28, 31]:\n",
    "        print('ID Trial Number: ', i, \"\\tCurrent Trial Number: \", curr_idx)\n",
    "        try:\n",
    "            print('id', np.array(id_events.iloc[id_trial].data), np.array(id_events.iloc[id_trials[i+1]].data))\n",
    "            print('current', np.array(current_events.iloc[current_trial].data), np.array(current_events.iloc[current_trials[curr_idx+1]].data))\n",
    "        except:\n",
    "            print('id', np.array(id_events.iloc[id_trial].data))\n",
    "            print('current', np.array(current_events.iloc[current_trial].data))\n",
    "\n",
    "        print()\n",
    "    \n",
    "    for idx, j in enumerate(id_trial):\n",
    "        try:\n",
    "            correct_current.append(current_trial[idx])\n",
    "            correct_id.append(j)\n",
    "        except:\n",
    "            pass\n",
    "#             print(i, np.array(id_events.iloc[id_trial+[j]].data))\n",
    "\n",
    "    if len(id_trial) > 1:\n",
    "        curr_idx += 1\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(current_events.iloc[current_trials[-3]].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_on_id = np.array(id_events.iloc[correct_id].data)[:len(samp_on)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_on_current = np.array(current_events.iloc[correct_current].data)[:len(samp_on)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samp_on_id), len(samp_on_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_id), len(correct_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "correct_id = []\n",
    "correct_current = []\n",
    "\n",
    "curr_idx = 0\n",
    "\n",
    "while np.all(np.array(current_events.iloc[current_trials[curr_idx]].data) == 1):\n",
    "    curr_idx += 1\n",
    "\n",
    "for i in range(len(id_trials)):\n",
    "    current_trial = current_trials[curr_idx]\n",
    "    id_trial = id_trials[i]\n",
    "    \n",
    "    if '' in np.array(id_events.iloc[id_trial].data):\n",
    "        continue\n",
    "\n",
    "    if len(id_trial) > 8:\n",
    "        id_trial = id_trial[-8:]\n",
    "        \n",
    "    \n",
    "    for idx, j in enumerate(id_trial):\n",
    "        try:\n",
    "            correct_current.append(current_trial[idx])\n",
    "            correct_id.append(j)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if len(id_trial) > 1:\n",
    "        curr_idx += 1\n",
    "        \n",
    "samp_on_id = np.array(id_events.iloc[correct_id].data)[:len(samp_on)]\n",
    "\n",
    "samp_on_current = np.array(current_events.iloc[correct_current].data)[:len(samp_on)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Artefact Delay Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_letters = np.array(['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "channel_numbers = np.arange(32)\n",
    "\n",
    "\n",
    "all_channels = np.array(np.meshgrid(channel_letters, channel_numbers))\n",
    "all_channels = np.core.defchararray.add(np.core.defchararray.add(all_channels[0],'-'),np.char.zfill(all_channels[1], 3))\n",
    "all_channels = all_channels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_delays = {}\n",
    "# artefact_delays = joblib.load('artefact_delays.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_directory_path = \"/braintree/data2/active/users/ssazaidi/projects/orthographic/monkeys/oleo/intanraw/oleo_orthographic_210719_145244/\"\n",
    "\n",
    "for channel_name in all_channels:\n",
    "    \n",
    "    %reset -f out \n",
    "    channel_name = channel_name.upper()\n",
    "    \n",
    "    if channel_name in artefact_delays:\n",
    "        continue\n",
    "    \n",
    "    filename = directory_path + 'amp-'+channel_name+'.dat' # amplifier channel data\n",
    "    # filename = 'oleo_normalizers_210208_134001/amp-C-022.dat'\n",
    "    fid = open(filename, 'r')\n",
    "    filesize = os.path.getsize(filename) # in bytes\n",
    "    num_samples = filesize // 2 # int16 = 2 bytes\n",
    "    v = np.fromfile(fid, 'int16', num_samples)\n",
    "    fid.close()\n",
    "\n",
    "\n",
    "    v = v * 0.195 # convert to microvolts\n",
    "\n",
    "    sub_samp_on = []\n",
    "    artefact_on = []\n",
    "    sub_samp_number = []\n",
    "\n",
    "\n",
    "    failed_samp_on = []\n",
    "    failed_stim_number = []\n",
    "\n",
    "    peaks, _ = find_peaks(np.abs(v), height=150)  # Find all peaks\n",
    "    peaks = np.asarray([p for p in peaks if np.abs(v[p]) > 100])  # Apply threshold\n",
    "    for idx, s in enumerate(samp_on):\n",
    "        try:\n",
    "            artefact_on.append(min(peaks[(peaks >= s-3_000) & (peaks < (s+2_000))]))\n",
    "            sub_samp_on.append(s)\n",
    "            sub_samp_number.append(idx)\n",
    "        except:\n",
    "    #         print('Missing stim on: ', s)\n",
    "            failed_samp_on.append(s)\n",
    "            failed_stim_number.append(idx)\n",
    "            pass\n",
    "    # len(artefact_on)    \n",
    "\n",
    "    samp_on_ = np.array(samp_on) * 1000 / samplingFrequency\n",
    "    samp_on_\n",
    "\n",
    "    sub_samp_on_ = np.array(sub_samp_on) * 1000 / samplingFrequency\n",
    "    sub_samp_on_\n",
    "\n",
    "    artefact_on_ = np.array(artefact_on) * 1000 / samplingFrequency\n",
    "    artefact_on_\n",
    "    # print(artefact_on,sub_samp_on)\n",
    "#     print(np.mean(artefact_on_ - sub_samp_on_)) # in ms)\n",
    "\n",
    "\n",
    "    artefact_delay = np.zeros_like(samp_on, dtype=float)\n",
    "\n",
    "    artefact_delay[sub_samp_number] = artefact_on_ - sub_samp_on_ # in ms)\n",
    "\n",
    "    artefact_delay[failed_stim_number] = np.nan\n",
    "\n",
    "    artefact_delays[channel_name] = artefact_delay\n",
    "\n",
    "    joblib.dump(artefact_delays, 'artefact_delays.pkl')\n",
    "\n",
    "all_delays = []\n",
    "for key in artefact_delays:\n",
    "    all_delays.append([artefact_delays[key]])\n",
    "    \n",
    "all_delays = np.concatenate(all_delays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((np.min(all_delays , axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin(np.min(all_delays , axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the neural data, we read the amplifier data files for each channel, for each port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# alt_directory_path = \"/braintree/data2/active/users/ssazaidi/projects/orthographic/monkeys/oleo/intanraw/oleo_orthographic_210719_145244/\"\n",
    "\n",
    "channel_name = 'F-031'\n",
    "filename = directory_path + 'amp-'+channel_name+'.dat' # amplifier channel data\n",
    "# filename = 'oleo_normalizers_210208_134001/amp-C-022.dat'\n",
    "fid = open(filename, 'r')\n",
    "filesize = os.path.getsize(filename) # in bytes\n",
    "num_samples = filesize // 2 # int16 = 2 bytes\n",
    "v = np.fromfile(fid, 'int16', num_samples)\n",
    "fid.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "v = v * 0.195 # convert to microvolts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "v2 = apply_bandpass(v, 20000,300,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our raw data looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# t = [x * 1./samplingFrequency for x in range(len(v))] # time steps\n",
    "t = np.arange(len(v))/samplingFrequency\n",
    "plt.plot(t, v)\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Voltage [uV]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_subsize = 3415000\n",
    "# end_subsize = 3418000\n",
    "# start_subsize = 6*20000\n",
    "# end_subsize = 8*20000\n",
    "# v_copy= np.copy(v[start_subsize:end_subsize])\n",
    "# t_ = t[start_subsize:end_subsize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artefact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_samp_on = []\n",
    "artefact_on = []\n",
    "sub_samp_number = []\n",
    "\n",
    "\n",
    "failed_samp_on = []\n",
    "failed_stim_number = []\n",
    "\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "for idx, s in enumerate(samp_on):\n",
    "    i = idx\n",
    "    i +=shift\n",
    "\n",
    "    sub_signal = v[samp_on[i]-pre_: samp_on[i]+post_]\n",
    "    band_pass_sub_signal = apply_bandpass(sub_signal, samplingFrequency, 300,5000)\n",
    "\n",
    "\n",
    "    peaks, _ = find_peaks(np.abs(band_pass_sub_signal), height=0)\n",
    "    peaks = np.asarray([p for p in peaks if np.abs(band_pass_sub_signal[p]) > 100])  # Apply threshold\n",
    "\n",
    "    try:\n",
    "        artefact_time = np.min(peaks)\n",
    "        artefact_on.append(artefact_time)\n",
    "        sub_samp_on.append(s)\n",
    "        sub_samp_number.append(idx)\n",
    "    except:\n",
    "#         print('Missing stim on: ', s)\n",
    "        failed_samp_on.append(s)\n",
    "        failed_stim_number.append(idx)\n",
    "        pass\n",
    "\n",
    "\n",
    "samp_on_ = np.array(samp_on) * 1000 / samplingFrequency\n",
    "samp_on_\n",
    "\n",
    "sub_samp_on_ = np.array(sub_samp_on) * 1000 / samplingFrequency\n",
    "sub_samp_on_\n",
    "\n",
    "artefact_on_ = 1000* (np.array(artefact_on)/ samplingFrequency - half_)\n",
    "artefact_on_\n",
    "# print(artefact_on,sub_samp_on)\n",
    "print(np.mean(artefact_on_ - sub_samp_on_)) # in ms)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_on_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(artefact_on_ - sub_samp_on_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sub_samp_on_- photodiode_on_[sub_samp_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_delay = np.zeros_like(samp_on, dtype=float)\n",
    "\n",
    "artefact_delay[sub_samp_number] = artefact_on_ - sub_samp_on_ # in ms)\n",
    "\n",
    "artefact_delay[failed_stim_number] = np.nan\n",
    "\n",
    "artefact_delays[channel_name] = artefact_delay\n",
    "\n",
    "joblib.dump(artefact_delays, 'artefact_delays.pkl')\n",
    "\n",
    "all_delays = []\n",
    "for key in artefact_delays:\n",
    "    all_delays.append([artefact_delays[key]])\n",
    "    \n",
    "all_delays = np.concatenate(all_delays, axis=0)\n",
    "\n",
    "\n",
    "plt.plot((np.mean(all_delays , axis = 0)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.array(id_events.iloc[id_trial].data) for id_trial in id_trials]\n",
    "id_events.iloc[correct_id].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(artefact_delay[np.array(id_events.iloc[correct_id].data)== 'd-008'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_samp_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 5000\n",
    "post_ = 5000\n",
    "length_ = pre_+post_\n",
    "half_ = (length_-post_)/(samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "for i in range(10):\n",
    "    \n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v[failed_samp_on[i+shift]-pre_:failed_samp_on[i+shift]+post_])\n",
    "    plt.plot(0,1, 'k*')\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[failed_samp_on[i+shift]-pre_: failed_samp_on[i+shift]+post_]*1000, alpha=0.5)\n",
    "    stim_number = failed_stim_number[i]\n",
    "    plt.title(str(stim_number)+ ' , ' + \n",
    "              str(id_events.iloc[correct_id[stim_number]].data) + ' , f' + \n",
    "              str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "              str(current_events.iloc[correct_current[stim_number]].data))\n",
    "    \n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_on[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "\n",
    "bad_samples = [6, 472, 2981,473, 3883, 3884]\n",
    "\n",
    "for idx in range(6):\n",
    "    i = idx\n",
    "    plt.subplot(6,6,i+1)\n",
    "    i +=shift\n",
    "    stim_number = bad_samples[i]\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v[samp_on[i]-pre_: samp_on[i]+post_])\n",
    "    plt.plot(0,1, 'k*')\n",
    "    \n",
    "#     plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[sub_samp_on[i]-pre_: sub_samp_on[i]+post_]*500, alpha=0.5)\n",
    "\n",
    "    plt.plot(artefact_on_[stim_number],0, 'r*')\n",
    "    plt.title(str(stim_number)+ ' , ' + \n",
    "              str(samp_on_id[stim_number]) + ' , f' + \n",
    "              str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "              str(samp_on_current[stim_number]))\n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_copy = np.copy(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(v_copy), np.mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, (v_copy))\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Voltage [mV]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correct_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().clear()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ = remove_artefacts(np.copy(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = remove_artefacts_all(np.copy(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(25,12), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.subplot(131)\n",
    "plt.plot(v)\n",
    "plt.subplot(132)\n",
    "plt.plot(v2)\n",
    "plt.subplot(133)\n",
    "plt.plot(v_)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(apply_bandpass(v2[:100000], 20000,300,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 5000\n",
    "post_ = 5000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "\n",
    "for idx in range(36):\n",
    "    i = idx\n",
    "    plt.subplot(6,6,i+1)\n",
    "    i +=shift\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),apply_bandpass(v_[sub_samp_on[i]-pre_: sub_samp_on[i]+post_],20000,1000,5000))\n",
    "#     plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_[sub_samp_on[i]-pre_: sub_samp_on[i]+post_])\n",
    "    plt.plot(0,1, 'k*')\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[sub_samp_on[i]-pre_: sub_samp_on[i]+post_], alpha=0.5)\n",
    "    stim_number = sub_samp_number[i]\n",
    "    plt.title(str(stim_number)+ ' , ' + \n",
    "              str(id_events.iloc[correct_id[stim_number]].data) + ' , f' + \n",
    "              str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "              str(current_events.iloc[correct_current[stim_number]].data))\n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 5000\n",
    "post_ = 5000\n",
    "length_ = pre_+post_\n",
    "half_ = (length_-post_)/(samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "for i in range(32):\n",
    "    \n",
    "    plt.subplot(6,6,i+1)\n",
    "    \n",
    "    i = i+shift\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),apply_bandpass(v_[failed_samp_on[i+shift]-pre_:failed_samp_on[i+shift]+post_],20000,1000,5000))\n",
    "    plt.plot(0,1, 'k*')\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[failed_samp_on[i+shift]-pre_: failed_samp_on[i+shift]+post_], alpha=0.5)\n",
    "    stim_number = failed_stim_number[i]\n",
    "    plt.title(str(stim_number)+ ' , ' + \n",
    "              str(id_events.iloc[correct_id[stim_number]].data) + ' , f' + \n",
    "              str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "              str(current_events.iloc[correct_current[stim_number]].data))\n",
    "    \n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "pre_ = 400\n",
    "post_ = 2000\n",
    "sub_signal = v[samp_on[i]-pre_: samp_on[i]+post_]\n",
    "peaks = find_peaks(-sub_signal, 150)\n",
    "# peaks = np.where(np.abs(sub_signal) > 150)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(sub_signal)\n",
    "plt.title(str(len(peaks[0])))\n",
    "print('Number of Peaks: ', len(peaks[0]))\n",
    "\n",
    "\n",
    "fs = 20000\n",
    "art_time_sec = 900/1e6\n",
    "art_len_pre = int(fs*art_time_sec/3)\n",
    "art_len_post = int(fs*2*art_time_sec/3)\n",
    "\n",
    "\n",
    "print('Artefact length: ', art_len_pre + art_len_post)\n",
    "\n",
    "\n",
    "\n",
    "start = -pre_\n",
    "x_ = []\n",
    "for i in peaks[0]:\n",
    "    x_.append(np.arange(start,i - pre_ - art_len_pre))\n",
    "    if i - pre_ > start:\n",
    "        start = i - pre_ + art_len_post\n",
    "x_.append(np.arange(start, post_))\n",
    "x = np.concatenate(x_)\n",
    "interpolator_signal = interpolate.interp1d(x, sub_signal[x+pre_])\n",
    "sig_interp = interpolator_signal(np.arange(-400,2000))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(apply_bandpass(sig_interp, 20000,1000,5000))\n",
    "plt.title(str(len(peaks[0])))\n",
    "\n",
    "# v[samp_on[i]-pre_: samp_on[i]+post_] = sig_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artefact Delay across channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samp_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(all_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_directory_path = \"/braintree/data2/active/users/ssazaidi/projects/orthographic/monkeys/oleo/intanraw/oleo_orthographic_210719_145244/\"\n",
    "\n",
    "num_channels = len(all_channels)\n",
    "num_sample_on = len(samp_on)\n",
    "\n",
    "\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "\n",
    "data_across_channels = np.zeros([num_channels, num_sample_on, length_])\n",
    "artefact_times = np.zeros([num_channels, num_sample_on])\n",
    "\n",
    "\n",
    "for ch_num, channel_name in enumerate(all_channels[:num_channels]):\n",
    "    \n",
    "    %reset -f out \n",
    "    channel_name = channel_name.upper()\n",
    "\n",
    "    \n",
    "    filename = directory_path + 'amp-'+channel_name+'.dat' # amplifier channel data\n",
    "    # filename = 'oleo_normalizers_210208_134001/amp-C-022.dat'\n",
    "    fid = open(filename, 'r')\n",
    "    filesize = os.path.getsize(filename) # in bytes\n",
    "    num_samples = filesize // 2 # int16 = 2 bytes\n",
    "    v = np.fromfile(fid, 'int16', num_samples)\n",
    "    fid.close()\n",
    "\n",
    "\n",
    "    v = v * 0.195 # convert to microvolts\n",
    "    \n",
    "    for idx in range(num_sample_on):\n",
    "        i = idx\n",
    "        i +=shift\n",
    "        \n",
    "        sub_signal = v[samp_on[i]-pre_: samp_on[i]+post_]\n",
    "        band_pass_sub_signal = apply_bandpass(sub_signal, samplingFrequency, 300,5000)\n",
    "        \n",
    "        data_across_channels[ch_num, idx, :] = sub_signal\n",
    "        peaks, _ = find_peaks(np.abs(band_pass_sub_signal), height=0)\n",
    "        peaks = np.asarray([p for p in peaks if np.abs(band_pass_sub_signal[p]) > 100])  # Apply threshold\n",
    "        \n",
    "        try:\n",
    "            artefact_time = np.min(peaks)\n",
    "            artefact_times[ch_num, idx] = artefact_time\n",
    "        except:\n",
    "            print(channel_name, idx)\n",
    "            artefact_times[ch_num, idx] = np.nan\n",
    "#         print('Artefact Time is: ', artefact_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup = {'data': data_across_channels, 'artefact_times': artefact_times}\n",
    "joblib.dump(backup, 'sub_sample_backup.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_times_ms = 1000*(artefact_times/samplingFrequency -half_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Artefact Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_letters = np.array(['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "channel_numbers = np.arange(32)\n",
    "\n",
    "\n",
    "all_channels = np.array(np.meshgrid(channel_letters, channel_numbers))\n",
    "all_channels = np.core.defchararray.add(np.core.defchararray.add(all_channels[0],'-'),np.char.zfill(all_channels[1], 3))\n",
    "all_channels = all_channels.flatten()\n",
    "print(all_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_files = [os.path.join('artefact_delays_'+date+'_'+i+'.pkl') for i in all_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where([i in  [\"a-001\", \"d-003\", \"b-003\", \"b-002\"] for i in all_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '210820'\n",
    "file_list = os.listdir(date)\n",
    "artefact_files = [i for i in file_list if 'artefact' in i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(artefact_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_times_ms = np.zeros([len(artefact_files), len(samp_on)]) \n",
    "data_across_channels = np.zeros([len(artefact_files), len(samp_on), length_])\n",
    "channel_names = []\n",
    "for i, artefact_file in enumerate(artefact_files):\n",
    "    try:\n",
    "        artefact_info = joblib.load(os.path.join(date, artefact_file))\n",
    "        artefact_times_ms[i,:] = artefact_info['artefact_delay']\n",
    "        channel_names.append(artefact_file.split('_')[-1].split('.')[0])\n",
    "        data_across_channels[i, :, :] = artefact_info['data']\n",
    "    except:\n",
    "        print(artefact_file.split('_')[-1].split('.')[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_times = artefact_times_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = plt.hist(artefact_times.flatten(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hstd = plt.hist(np.nanmedian(artefact_times, axis=0), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.nanmedian(artefact_times, axis=0) < -40)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_times, np.nanmean(artefact_times, axis=0), np.nanmax(artefact_times, axis=0), np.nanmin(artefact_times, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.sum(artefact_times < np.nanmean(artefact_times, axis=0)-2, axis=0) >8)\n",
    "# plt.hist(np.where(artefact_times < np.nanmean(artefact_times, axis=0)-2)[1], 5312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_ids = samp_on_id[np.where(np.sum(np.isnan(artefact_times), axis=0))]\n",
    "failed_currents = samp_on_current[np.where(np.sum(np.isnan(artefact_times), axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = pd.DataFrame({'ids': failed_ids, 'currents': failed_currents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "ax = sns.histplot(data=failed_df, x=\"ids\", hue=\"currents\", palette='inferno', multiple='dodge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.hist(samp_on_id[np.where(np.sum(np.isnan(artefact_times), axis=0))], 'stone', rwidth=0.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  plt.bar(np.arange(num_sample_on)+1, np.sum(np.isnan(artefact_times), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sub_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_samples = np.where(np.isnan(artefact_times))\n",
    "other_bad = [s for s in bad_samples[1] if s not in b_31_nums[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad_samples[1][other_bad[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(all_channels == 'b-031')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_31_nums = np.where(samp_on_id == 'b-031')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_across_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "fig=plt.figure(figsize=(25,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "t = 1000*(np.arange(length_)/samplingFrequency -half_)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "sub_channels = np.arange(16,21)\n",
    "sub_samples = [ 8,   61,   63,  157,  192]#, 2055, 2521, 2931, 3530, 3859, 3883,  3884, 4372, 4644, 4883, 4886]\n",
    "\n",
    "# sub_channels = np.unique(bad_samples[1][other_bad])[:5]\n",
    "# sub_samples = np.unique([other_bad])[:8]\n",
    "\n",
    "\n",
    "\n",
    "sub_num_channels = len(sub_channels)\n",
    "sub_num_sample_on = len(sub_samples)\n",
    "\n",
    "for i, ch in enumerate(sub_channels):\n",
    "    for j, sp in enumerate(sub_samples):\n",
    "        plt.subplot(sub_num_channels, sub_num_sample_on, (j+1) + i*sub_num_sample_on)\n",
    "        plt.plot(t, apply_bandpass(data_across_channels[ch,sp], samplingFrequency, 300, 5000))\n",
    "#         plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[samp_on[sp]-pre_: samp_on[sp]+post_]*50, alpha=0.5)\n",
    "        plt.plot(0,0, 'k*')\n",
    "        plt.plot(artefact_times[ch][sp], 0, 'r*')\n",
    "        \n",
    "        \n",
    "        plt.title(samp_on_id[sp]+' , '+str(artefact_times[ch][sp]) + ' Curr: ' + str(samp_on_current[sp]))\n",
    "        plt.ylabel(channel_names[ch])\n",
    "#         plt.ylim([-3000,3000])\n",
    "#         plt.yticks([])\n",
    "        plt.grid(True)\n",
    "        count +=1\n",
    "plt.suptitle('Stim Locked Signals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "fig=plt.figure(figsize=(25,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "t = 1000*(np.arange(length_)/samplingFrequency -half_)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "sub_channels = np.arange(16,21)\n",
    "sub_samples = [ 8,   61,   63,  157,  192]#, 2055, 2521, 2931, 3530, 3859, 3883,  3884, 4372, 4644, 4883, 4886]\n",
    "\n",
    "# sub_channels = np.unique(bad_samples[1][other_bad])[:5]\n",
    "# sub_samples = np.unique([other_bad])[:8]\n",
    "\n",
    "\n",
    "\n",
    "sub_num_channels = len(sub_channels)\n",
    "sub_num_sample_on = len(sub_samples)\n",
    "\n",
    "for i, ch in enumerate(sub_channels):\n",
    "    for j, sp in enumerate(sub_samples):\n",
    "        plt.subplot(sub_num_channels, sub_num_sample_on, (j+1) + i*sub_num_sample_on)\n",
    "        plt.plot(t, apply_bandpass(remove_artefacts(data_across_channels[ch,sp]), samplingFrequency, 300, 5000))\n",
    "#         plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[samp_on[sp]-pre_: samp_on[sp]+post_]*50, alpha=0.5)\n",
    "        plt.plot(0,0, 'k*')\n",
    "        plt.plot(artefact_times[ch][sp], 0, 'r*')\n",
    "        \n",
    "        \n",
    "        plt.title(samp_on_id[sp]+' , '+str(artefact_times[ch][sp]) + ' Curr: ' + str(samp_on_current[sp]))\n",
    "        plt.ylabel(channel_names[ch])\n",
    "#         plt.ylim([-3000,3000])\n",
    "#         plt.yticks([])\n",
    "        plt.grid(True)\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please work for the love of god! Artefact Delay Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '210820'\n",
    "artefact_times = joblib.load(os.path.join(date, 'artefact_time_'+date+'.pkl')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artefact_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f out\n",
    "%reset -f in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 200\n",
    "post_ = 100\n",
    "length_ = pre_+post_\n",
    "half_ = (length_-post_)/(samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "for i in range(32):\n",
    "    \n",
    "    plt.subplot(6,6,i+1)\n",
    "    \n",
    "    i = i+shift\n",
    "#     plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),apply_bandpass(v[artefact_times[i+shift]-pre_:artefact_times[i+shift]+post_],20000,1000,5000))\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_), apply_bandpass(v[artefact_times[i+shift]-pre_:artefact_times[i+shift]+post_],20000,1000,5000))\n",
    "    plt.plot(0,0, 'r*')\n",
    "#     plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[failed_samp_on[i+shift]-pre_: failed_samp_on[i+shift]+post_], alpha=0.5)\n",
    "    stim_number = i\n",
    "#     plt.title(str(stim_number)+ ' , ' + \n",
    "#               str(id_events.iloc[correct_id[stim_number]].data) + ' , f' + \n",
    "#               str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "#               str(current_events.iloc[correct_current[stim_number]].data))\n",
    "    \n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,25), dpi= 100, facecolor='w', edgecolor='k')\n",
    "pre_ = 1000\n",
    "post_ = 2000\n",
    "length_ = pre_+post_\n",
    "half_ = length_/(2*samplingFrequency)\n",
    "\n",
    "shift = 0\n",
    "\n",
    "for idx in range(5):\n",
    "    i = idx\n",
    "    i +=shift\n",
    "    plt.plot(1000*(np.arange(length_)/samplingFrequency -half_),v_diode[sub_samp_on[i]-pre_: sub_samp_on[i]+post_]*500, alpha=0.5)\n",
    "    stim_number = sub_samp_number[i]\n",
    "    plt.title(str(stim_number)+ ' , ' + \n",
    "              str(id_events.iloc[correct_id[stim_number]].data) + ' , f' + \n",
    "              str(key_events.iloc[correct_id[stim_number]].data) + ' , \\n' + \n",
    "              str(current_events.iloc[correct_current[stim_number]].data))\n",
    "    plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nrSegments = 10\n",
    "nrPerSegment = int(np.ceil(len(v) / nrSegments))\n",
    "\n",
    "print(nrPerSegment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the frequency spectogram of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spikeTimesMS = []\n",
    "\n",
    "for i in range(nrSegments):\n",
    "#     print( i*nrPerSegment, (i+1)*nrPerSegment )\n",
    "    timeIdxs = 1000 * np.arange(i*nrPerSegment, (i+1)*nrPerSegment) / samplingFrequency # in milliseconds\n",
    "\n",
    "    # Apply IIR Filter. Maybe not the best thing since\n",
    "    # this filter introduces refractory period artifacts, and\n",
    "    # FIR should be preferred\n",
    "    v1 = apply_bandpass(v[i*nrPerSegment:(i+1)*nrPerSegment], samplingFrequency, 300, 6000)\n",
    "    v2 = v1 - np.nanmean(v1)\n",
    "\n",
    "    # We threshold at 3*sd\n",
    "    # The denominator 0.6745 comes from some old neuroscience\n",
    "    # paper which shows that when you have spikey data, correcting\n",
    "    # with this number is better than just using plain standard\n",
    "    # deviation value\n",
    "    noiseLevel =  -3 * np.median(np.abs(v2))/0.6745\n",
    "    outside = np.array(v2) < noiseLevel # Spits a logical array\n",
    "    outside = outside.astype(int) # Convert logical array to int array for diff to work\n",
    "\n",
    "    cross = np.concatenate( ([outside[0]], np.diff(outside, n=1) > 0) )\n",
    "\n",
    "    idxs = np.nonzero(cross)[0]\n",
    "    spikeTimesMS.extend(timeIdxs[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( len(spikeTimesMS) )\n",
    "print( spikeTimesMS[0:5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let us look how the filtered signal looks like. The grey line is our threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 3 # We will just look at the first segment\n",
    "v1 = apply_bandpass(v[i*nrPerSegment:(i+1)*nrPerSegment], samplingFrequency, 300, 6000)\n",
    "v2 = v1 - np.nanmean(v1)\n",
    "t = 1000 * np.arange(i*nrPerSegment, (i+1)*nrPerSegment) / samplingFrequency # in milliseconds\n",
    "\n",
    "plt.plot(t[:10000], v2[:10000])\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Voltage [mV]')\n",
    "plt.axhline(y=-3*np.median(np.abs(v2))/0.6745, color='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add a raster plot to show at which points we're detecting spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(211)\n",
    "\n",
    "plt.plot(t[:10000], v2[:10000])\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Voltage [mV]')\n",
    "plt.xlim(0, t[9999])\n",
    "plt.axhline(y=-3*np.median(np.abs(v2))/0.6745, color='grey')\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.vlines(spikeTimesMS[:10000], 0, 1)\n",
    "plt.xlim(0, t[9999])\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us make this a more intuitive plot. We will pick one image, and for all trials of that image (there should be 6 of them since this FBOP data has 6 repetitions), we will make a raster plot.\n",
    "\n",
    "Let us pick image 1, which is a monkey face.\n",
    "\n",
    "For reference,\n",
    "1-20 = faces\n",
    "29-40 = bodies\n",
    "41-60 = objects\n",
    "61-80 = more faces\n",
    "81-100 = places\n",
    "101 = grey\n",
    "102-126 = normalizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(id_events.iloc[correct_id].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get all samp_on times for image 1\n",
    "im1_idxs = np.where(np.array(id_events.iloc[correct_id].data) == 'a-031')[0]\n",
    "im1_samp_on = np.array(samp_on)[im1_idxs]\n",
    "\n",
    "# print(im1_samp_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max_idx - min_idx) * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We're going to plot 200ms interval from stimulus onset time\n",
    "intervalSize = .25\n",
    "\n",
    "min_idxs = []\n",
    "max_idxs = []\n",
    "\n",
    "for x in im1_samp_on:\n",
    "    x /= 1000.0 # Convert to sec\n",
    "    min_idx = min(np.where(t >= x-0.1)[0])\n",
    "    max_idx = max(np.where(t <= x + intervalSize)[0])\n",
    "#     print(min_idx, max_idx, (max_idx - min_idx) * 0.05, round((max_idx - min_idx) * 0.05, 2), intervalSize * 1000 )\n",
    "#     assert( round((max_idx - min_idx) * 0.05, 2) == intervalSize ) # Check that we have a 200ms interval\n",
    "\n",
    "    min_idxs.append(min_idx)\n",
    "    max_idxs.append(max_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(211)\n",
    "\n",
    "# For plotting purposes, we're going to threshold the entire\n",
    "# signal in one segment and not ten\n",
    "v1 = apply_bandpass(v, samplingFrequency, 1000, 6000)\n",
    "v2 = v1 - np.nanmean(v1)\n",
    "\n",
    "plt.plot(t[min_idxs[0]:max_idxs[0]], v[min_idxs[0]:max_idxs[0]])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Voltage [mV]')\n",
    "\n",
    "plt.axvspan(t[min_idxs[0]] + 0.07, t[min_idxs[0]] + .17, alpha=0.15, color='g')\n",
    "plt.axhline(y=-3*np.median(np.abs(v2))/0.6745, color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print( min_idxs, max_idxs )\n",
    "plt.plot(v[1331091:1331091+2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MWorks data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use MWorks' data analysis tools for Python, you need to make the MWorks package available to your Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/Library/Application Support/MWorks/Scripting/Python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawDataPath = '/Users/monkeyd.mani/Dropbox (MIT)/8_10_2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(fixation_events) == len(image_presented_events) # check for equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_order = []\n",
    "fixation_correct = []\n",
    "\n",
    "for image_presented, fixation in zip(image_presented_events, fixation_events):\n",
    "    if image_presented.data is -1: # skip if no image presented\n",
    "        continue\n",
    "    image_order.append(image_presented.data)\n",
    "    fixation_correct.append(fixation.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(image_order) == len(fixation_correct) # check for equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(fixation_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(image_order[0:5])\n",
    "print(fixation_correct[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "\n",
    "\n",
    "mdata = {'image_order': image_order, 'fixation_correct': fixation_correct}\n",
    "io.savemat('mworksdata.mat', mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "currents = [1,2,4,8,12,16,20,24,28, 32, 36, 40,44]\n",
    "all_channels_unique = ['a-000', 'd-008',  'd-018', 'a-016', 'd-000', \n",
    "                     'a-024', 'd-016', 'a-031', 'd-025', 'a-022', 'd-005', 'b-031', \n",
    "                                                            'b-000', 'd-010', 'a-028']\n",
    "\n",
    "\n",
    "#### FOR STIM DEMO\n",
    "\n",
    "# all_channels_unique = ['a-000', 'b-008',  'b-018', 'a-016', 'b-000', \n",
    "#                      'a-024', 'b-016', 'a-031', 'b-025', 'a-022', 'b-005', 'b-031', \n",
    "#                                                             'b-000', 'b-010', 'a-028']\n",
    "\n",
    "\n",
    "\n",
    "all_channels = list(product(all_channels_unique, currents))\n",
    "\n",
    "all_refs = ['a-008', 'b-008', 'a-006', 'b-020', 'a-009', 'b-026', 'b-022']\n",
    "\n",
    " # Update this list based on the electrodes you want to stimulate (Use LGA to Headstage map)\n",
    "\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(all_channels).reshape(-1,13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(currents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channel_ids[0] in all_channel_ids[-8:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "all_channel_ids = np.array([np.random.permutation(all_channels_unique) for i in range(13)]).flatten()\n",
    "i = 0\n",
    "chan = all_channel_ids[i]\n",
    "num_good_ones = 0\n",
    "\n",
    "\n",
    "back_list = all_channel_ids[i-8:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "all_channel_ids = np.array([np.random.permutation(all_channels_unique) for i in range(13)]).flatten()\n",
    "i = 0\n",
    "chan = all_channel_ids[i]\n",
    "num_good_ones = 0\n",
    "back_list = all_channel_ids[i-8:None]\n",
    "\n",
    "\n",
    "while chan not in back_list or i < 195:\n",
    "    if chan in back_list:\n",
    "        temp = np.copy(chan)\n",
    "        swap_num = 1\n",
    "        while all_channel_ids[i+swap_num] in back_list:\n",
    "            swap_num += 1\n",
    "        all_channel_ids[i] = all_channel_ids[i+swap_num]\n",
    "        all_channel_ids[i+swap_num] = temp\n",
    "        i = 0\n",
    "        num_good_ones = 0\n",
    "        chan = all_channel_ids[i]\n",
    "    else:\n",
    "        i = (i+1)%len(all_channel_ids)\n",
    "        num_good_ones += 1\n",
    "        try:\n",
    "            chan = all_channel_ids[i]\n",
    "        except:\n",
    "            break\n",
    "    if i < 8:\n",
    "        back_list = all_channel_ids[i-8:None]\n",
    "    else:\n",
    "        back_list = all_channel_ids[i-8:i]\n",
    "    \n",
    "    if chan not in back_list and num_good_ones > 205:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "all_currents = np.zeros(all_channel_ids.shape)\n",
    "for channel in all_channels_unique:\n",
    "    idxs = np.where(all_channel_ids == channel)\n",
    "    all_currents[idxs] = np.random.permutation(currents)\n",
    "all_channels = [(i, j) for i,j in zip(list(all_channel_ids), list(all_currents.astype(int)))]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels[-8:] , all_channels[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.sample(all_channels_unique, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_idx = 0\n",
    "stim_key = 1\n",
    "\n",
    "all_channels[(stim_idx+int(stim_key)-1)%len(all_channels)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_salpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ctypeslib.load_library('../../salpa', os.path.dirname('../../python_salpa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libname = 'libsalpa'\n",
    "loader_path = os.path.dirname('../../python_salpa')\n",
    "ext = os.path.splitext(libname)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ext:\n",
    "    # Try to load library with platform-specific name, otherwise\n",
    "    # default to libname.[so|pyd].  Sometimes, these files are built\n",
    "    # erroneously on non-linux platforms.\n",
    "    from numpy.distutils.misc_util import get_shared_lib_extension\n",
    "    so_ext = get_shared_lib_extension()\n",
    "    libname_ext = [libname + so_ext]\n",
    "    # mac, windows and linux >= py3.2 shared library and loadable\n",
    "    # module have different extensions so try both\n",
    "    so_ext2 = get_shared_lib_extension(is_python_ext=True)\n",
    "    if not so_ext2 == so_ext:\n",
    "        libname_ext.insert(0, libname + so_ext2)\n",
    "else:\n",
    "    libname_ext = [libname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libname_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_path = os.path.abspath(loader_path)\n",
    "if not os.path.isdir(loader_path):\n",
    "    libdir = os.path.dirname(loader_path)\n",
    "else:\n",
    "    libdir = loader_path\n",
    "\n",
    "for ln in libname_ext:\n",
    "    libpath = os.path.join(libdir, ln)\n",
    "    if os.path.exists(libpath):\n",
    "        print( ctypes.cdll[libpath])\n",
    "        ## if no successful return in the libname_ext loop:\n",
    "# raise OSError(\"no file with expected extension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_on_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
